{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8929453,"sourceType":"datasetVersion","datasetId":5371535},{"sourceId":8929525,"sourceType":"datasetVersion","datasetId":5371579}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimages_v = [f'/kaggle/input/cycleganvangogf/{pic}' for pic in os.listdir('/kaggle/input/cycleganvangogf')]\nimages_r = [f'/kaggle/input/cylceganreal/{pic}' for pic in os.listdir('/kaggle/input/cylceganreal')]\nif '/kaggle/input/cycleganvangogf/hi.py' in images_v: images_v.remove('/kaggle/input/cycleganvangogf/hi.py')\n\n    \nprint(\"no of vanggogf images \", len(images_v))\nprint(\"no of real images \", len(images_r))","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:14:56.708517Z","iopub.execute_input":"2024-07-12T03:14:56.709238Z","iopub.status.idle":"2024-07-12T03:14:57.508267Z","shell.execute_reply.started":"2024-07-12T03:14:56.709208Z","shell.execute_reply":"2024-07-12T03:14:57.507338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discriminator\nimport torch\nimport torch.nn as nn\n\nclass DBlock(nn.Module):\n    def __init__(self,in_channels,out_channels, stride):\n        super().__init__()\n        \n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=4,\n                stride=stride,\n                padding=1,\n                bias=True,\n                padding_mode='reflect'\n            ),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.2)\n        )\n        \n    def forward(self, x): \n        return self.conv(x)\n    \nclass Discriminator(nn.Module):\n    def __init__(self,in_channels, features = [64,128,256,512]):\n        super().__init__()\n        \n        layers = list()\n        init_channels = in_channels\n        in_channels = features[0]\n        \n        for feature in features[1:]:\n            layers.append(\n                DBlock(\n                    in_channels=in_channels,\n                    out_channels=feature,\n                    stride = 1 if feature==features[-1] else 2\n                )\n            )\n            in_channels = feature\n            \n        self.discriminator = nn.Sequential(\n            #initial\n            nn.Sequential(\n                nn.Conv2d(\n                    in_channels=init_channels,\n                    out_channels=features[0],\n                    kernel_size=4,\n                    stride=2,\n                    padding=1,\n                    padding_mode='reflect'\n                ),\n                nn.LeakyReLU(0.2)\n            ),\n            #intermediate\n            nn.Sequential(*layers),\n            #final\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels = 1,\n                kernel_size=4,\n                stride = 1,\n                padding=1,\n                padding_mode='reflect'\n            )\n        )\n        \n    def forward(self, x):\n        return self.discriminator(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:14:57.510031Z","iopub.execute_input":"2024-07-12T03:14:57.510338Z","iopub.status.idle":"2024-07-12T03:15:01.389936Z","shell.execute_reply.started":"2024-07-12T03:14:57.510306Z","shell.execute_reply":"2024-07-12T03:15:01.388968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GBlock(nn.Module):\n    def __init__(self,in_channels, out_channels, down = True, use_act = True, **kwargs):\n        super().__init__()\n        \n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, padding_mode='reflect', **kwargs)\n            if down\n            else nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, **kwargs),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity()\n        )\n        \n    def forward(self, x): \n        return self.conv(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self,channels):\n        super().__init__()\n        \n        self.block = nn.Sequential(\n            GBlock(in_channels=channels,out_channels=channels,use_act=True,kernel_size = 3,padding=1),\n            GBlock(in_channels=channels,out_channels=channels,use_act=False,kernel_size = 3, padding=1),\n        )\n        \n    def forward(self, x): \n        return x + self.block(x)\n    \nclass Generator(nn.Module):\n        def __init__(self,in_channels,num_residuals=9):\n            super().__init__()\n            \n            self.generator = nn.Sequential(\n                nn.Conv2d(in_channels,64,kernel_size=7,stride=1, padding=3, padding_mode='reflect'),\n                nn.ReLU(inplace=True),\n                GBlock(64,128,down=True, use_act = True,kernel_size = 3,stride = 2,padding = 1),\n                GBlock(128,256,down=True, use_act = True,kernel_size = 3,stride = 2,padding = 1),\n                *([ResidualBlock(256)]*num_residuals),\n                GBlock(256,128,down=False, kernel_size = 3, stride = 2, padding=1,output_padding=1),\n                GBlock(128,64,down=False, kernel_size = 3, stride = 2, padding=1,output_padding=1),\n                nn.Conv2d(64,3,7,1,3,padding_mode=\"reflect\")\n            )\n            \n        def forward(self, x): \n            return self.generator(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:15:01.392969Z","iopub.execute_input":"2024-07-12T03:15:01.393449Z","iopub.status.idle":"2024-07-12T03:15:01.407027Z","shell.execute_reply.started":"2024-07-12T03:15:01.393415Z","shell.execute_reply":"2024-07-12T03:15:01.406153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nimport os\nfrom typing import Callable\nimport torch\n\n\nclass Config:\n    if not os.path.isdir(\"VangGoghGAN\"):\n        os.mkdir(\"VangGoghGAN\")\n    if not os.path.isdir(\"VangGoghGAN/checkpoints\"):\n        os.mkdir(\"VangGoghGAN/checkpoints\")\n    if not os.path.isdir(\"VangGoghGAN/gen_VangGogh\"):\n        os.mkdir(\"VangGoghGAN/gen_VangGogh\")\n    if not os.path.isdir(\"VangGoghGAN/gen_photo\"):\n        os.mkdir(\"VangGoghGAN/gen_photo\")\n\n\n    LEARNING_RATE:float = 0.0002\n    BETA_1:float = 0.5\n    BETA_2:float = 0.999\n    LAMBDA_CYCLE:int = 10\n    LAMBDA_IDENTITY:int = 5\n    NUM_EPOCHS:int = 20\n    BATCH_SIZE:int = 1\n\n    SAVE_MODEL:bool = True\n    LOAD_MODEL:bool = False\n\n    CHECKPOINT_GEN_VANGGOGH:Callable[..., str] = f'VangGoghGAN/checkpoints/gen_VangGogh.pth'\n    CHECKPOINT_DIS_VANGGOGH:Callable[..., str] = f'VangGoghGAN/checkpoints/dis_VangGogh.pth'\n    CHECKPOINT_GEN_PHOTO:Callable[..., str] = f'VangGoghGAN/checkpoints/gen_photo.pth'\n    CHECKPOINT_DIS_PHOTO:Callable[..., str] = f'VangGoghGAN/checkpoints/dis_photo.pth'\n\n    DEVICE:str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    VANGGOGF_SAVED_IMAGES:str = \"VangGoghGAN/gen_VangGogh\"\n    PHOTO_SAVED_IMAGES:str = \"VangGoghGAN/gen_photo\"\n\n    preprocess:transforms.transforms.Compose = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Resize((256, 256)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:15:01.409470Z","iopub.execute_input":"2024-07-12T03:15:01.409720Z","iopub.status.idle":"2024-07-12T03:15:03.177227Z","shell.execute_reply.started":"2024-07-12T03:15:01.409699Z","shell.execute_reply":"2024-07-12T03:15:03.176229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nconfig = Config()\n\n\nclass Utils:\n    def save(self, model, epoch, file_name)->None:\n        checkpoint = {\n            \"model\":model.state_dict(),\n            \"epoch\":epoch,\n        }\n        torch.save(checkpoint,file_name) \n        print('__finished saving checkpoint__')\n\n        \n        \n    def load(self, model, file_name)->None: \n        checkpoint = torch.load(file_name, map_location = config.DEVICE)\n        model.load_state_dict(checkpoint['model'])\n        print('__finished loading checkpoint__')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:15:03.178404Z","iopub.execute_input":"2024-07-12T03:15:03.178878Z","iopub.status.idle":"2024-07-12T03:15:03.185347Z","shell.execute_reply.started":"2024-07-12T03:15:03.178845Z","shell.execute_reply":"2024-07-12T03:15:03.184249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nconfig = Config()\n\n\nclass PhotoToVanggogfDataset(Dataset):\n    def __init__(self, vanggogf_photos, real_photos, transform:bool = True)->None:\n        self.vanggohf_photos = vanggogf_photos\n        self.real_photos = real_photos\n        self.transform = transform\n\n    def __len__(self)->int:\n        return max(len(self.vanggohf_photos), len(self.real_photos))\n\n    def __getitem__(self, idx)->tuple:\n        vanggogf_img = Image.open(self.vanggohf_photos[idx%len(self.vanggohf_photos)])\n        real_img = Image.open(self.real_photos[idx%len(self.real_photos)])\n        if self.transform:\n            real_img = config.preprocess(real_img)\n            vanggogf_img = config.preprocess(vanggogf_img)\n\n        return (real_img, vanggogf_img)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:15:03.186501Z","iopub.execute_input":"2024-07-12T03:15:03.186796Z","iopub.status.idle":"2024-07-12T03:15:03.197164Z","shell.execute_reply.started":"2024-07-12T03:15:03.186774Z","shell.execute_reply":"2024-07-12T03:15:03.196342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport os\nfrom torchvision.utils import save_image\n\nfrom tqdm import tqdm\n\nconfig = Config()\nutils = Utils()\n\n\nclass Trainer:\n    def train_epoch(self, \n                    config, \n                    disc_V, \n                    gen_V, \n                    disc_R, \n                    gen_R, \n                    trainloader, \n                    opt_disc, \n                    opt_gen, \n                    l1_loss, \n                    bce_loss, \n                    d_scaler = torch.cuda.amp.GradScaler(),\n                    g_scaler = torch.cuda.amp.GradScaler()\n                    ):\n        \n        discriminator_loss_epoch = 0\n        generator_loss_epoch = 0\n\n        loader = tqdm(trainloader, colour=\"blue\")\n        for idx, (real_img, vanggogf_img) in enumerate(loader):\n            real_img = real_img.to(config.DEVICE)\n            vanggogf_img = vanggogf_img.to(config.DEVICE)\n\n            # training discriminator\n            with torch.cuda.amp.autocast():\n\n                # disc_V loss --> true vanggogf\n                fake_v = gen_V(real_img)\n                disc_v_fake_score = disc_V(fake_v.detach())\n                disc_v_real_score = disc_V(vanggogf_img)\n                disc_v_fake_loss = bce_loss(disc_v_fake_score, torch.zeros_like(disc_v_fake_score))\n                disc_v_real_loss = bce_loss(disc_v_real_score, torch.ones_like(disc_v_real_score))\n                disc_v_loss = disc_v_real_loss + disc_v_fake_loss\n\n                # disc_R loss --> true real\n                fake_r = gen_R(vanggogf_img)\n                disc_r_fake_score = disc_R(fake_r.detach())\n                disc_r_real_score = disc_R(real_img)\n                disc_r_fake_loss = bce_loss(disc_r_fake_score, torch.zeros_like(disc_r_fake_score))\n                disc_r_real_loss = bce_loss(disc_r_real_score, torch.ones_like(disc_r_real_score))\n                disc_r_loss = disc_r_real_loss + disc_r_fake_loss\n                \n                disc_loss = (disc_v_loss + disc_r_loss) / 2\n                discriminator_loss_epoch += disc_loss.item()\n            \n            opt_disc.zero_grad()\n            d_scaler.scale(disc_loss).backward(retain_graph=True)\n            d_scaler.step(opt_disc)\n            d_scaler.update()\n\n            # training generator\n            with torch.cuda.amp.autocast():\n                disc_fake_v = disc_V(fake_v)\n                disc_fake_r = disc_R(fake_r)\n\n                # normal gan loss\n                gen_loss_v = bce_loss(disc_fake_v, torch.ones_like(disc_fake_v))\n                gen_loss_r = bce_loss(disc_fake_r, torch.ones_like(disc_fake_r))\n\n                # cycle loss\n                cycle_loss_v = l1_loss(real_img, gen_R(fake_v))\n                cycle_loss_r = l1_loss(vanggogf_img, gen_V(fake_r))\n\n                # identity loss\n                indentity_loss_v = l1_loss(vanggogf_img, gen_V(vanggogf_img))\n                indentity_loss_r = l1_loss(real_img, gen_R(real_img))\n\n                gen_loss = gen_loss_v + gen_loss_r + (cycle_loss_v + cycle_loss_r) * config.LAMBDA_CYCLE + (indentity_loss_v + indentity_loss_r) * config.LAMBDA_IDENTITY\n                generator_loss_epoch = gen_loss.item()\n\n            opt_gen.zero_grad()\n            g_scaler.scale(gen_loss).backward()\n            g_scaler.step(opt_gen)\n            g_scaler.update()\n\n            if not idx%200:\n                save_image(fake_v*0.5+0.5,f\"{config.VANGGOGF_SAVED_IMAGES}/{idx}.png\")\n                save_image(fake_r*0.5+0.5,f\"{config.PHOTO_SAVED_IMAGES}/{idx}.png\")\n\n            loader.set_postfix(\n                disc_loss = f\"{disc_loss.item():.4f}\",\n                gen_loss = f\"{gen_loss.item():.4f}\"\n            )\n\n        return discriminator_loss_epoch/len(trainloader),generator_loss_epoch/len(trainloader)\n\n    def train(self):\n        disc_V = Discriminator(in_channels=3).to(config.DEVICE)\n        gen_V = Generator(in_channels=3).to(config.DEVICE)\n\n        disc_R = Discriminator(in_channels=3).to(config.DEVICE)\n        gen_R = Generator(in_channels=3).to(config.DEVICE)\n        \n        opt_disc = torch.optim.Adam(\n            list(disc_V.parameters()) + list(disc_R.parameters()),\n            lr = config.LEARNING_RATE,\n            betas = (config.BETA_1, config.BETA_2)\n        )\n        opt_gen = torch.optim.Adam(\n            list(gen_V.parameters()) + list(gen_R.parameters()),\n            lr = config.LEARNING_RATE,\n            betas = (config.BETA_1, config.BETA_2)\n        )\n\n        l1_loss = nn.L1Loss()\n        bce_loss = nn.BCEWithLogitsLoss()\n        if config.LOAD_MODEL:\n            utils.load(\n                disc_V,\n                config.CHECKPOINT_DIS_VANGGOGH\n            )\n\n            utils.load(\n                disc_R,\n                config.CHECKPOINT_DIS_PHOTO\n            )\n\n            utils.load(\n                gen_V,\n                config.CHECKPOINT_GEN_VANGGOGH\n            )\n\n            utils.load(\n                gen_R,\n               config.CHECKPOINT_GEN_PHOTO\n            )\n            \n        \n        try:\n            trainset = PhotoToVanggogfDataset(images_v, images_r, transform=True)\n            trainloader = torch.utils.data.DataLoader(\n                trainset,\n                batch_size = config.BATCH_SIZE,\n                shuffle = True\n            )\n\n       \n        except ValueError as e:\n            print(e)\n            return\n        \n        generator_loss = list()\n        discriminator_loss = list()\n        print(\"__Training started__\")\n\n        for epoch in range(config.NUM_EPOCHS):\n            print(f\"Epoch{epoch + 1}/{config.NUM_EPOCHS}\")\n            \n            gen_loss, disc_loss = self.train_epoch(\n                config = config,\n                disc_V = disc_V, \n                gen_V = gen_V, \n                disc_R = disc_R,  \n                gen_R = gen_R, \n                trainloader = trainloader, \n                opt_disc = opt_disc, \n                opt_gen = opt_gen, \n                l1_loss = l1_loss, \n                bce_loss = bce_loss, \n            )\n\n            generator_loss.append(gen_loss)\n            discriminator_loss.append(disc_loss)\n\n            if config.SAVE_MODEL:\n                if not os.path.isdir(f'VangGoghGAN/checkpoints'):\n                    os.mkdir(f'VangGoghGAN/checkpoints')\n                \n            utils.save(\n                disc_V,\n                epoch,\n                config.CHECKPOINT_DIS_VANGGOGH\n            )\n            utils.save(\n                disc_R,\n                epoch,\n                config.CHECKPOINT_DIS_PHOTO\n            )\n            utils.save(\n                gen_V,\n                epoch,\n                config.CHECKPOINT_GEN_VANGGOGH\n            )\n            utils.save(\n                gen_R,\n                epoch,\n                config.CHECKPOINT_GEN_PHOTO\n            )\n\n        print(\"__Training Complete__\")\n       \n        print(\"__plotting loss curves__\")\n        plt.figure(figsize=(30,30))\n        plt.plot(generator_loss,color=\"red\")\n        plt.plot(discriminator_loss,color='blue')\n        plt.legend(['gen_loss','disc_loss'])\n        plt.title('LOSS vs EPOCH',fontdict={'fontsize':10})\n        plt.xlabel('EPOCH')\n        plt.ylabel('LOSS')\n        plt.xticks(range(0, config.NUM_EPOCHS+1 , 1),fontsize=10)\n        plt.yticks(fontsize=10)\n        plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:15:03.198797Z","iopub.execute_input":"2024-07-12T03:15:03.199165Z","iopub.status.idle":"2024-07-12T03:15:03.230541Z","shell.execute_reply.started":"2024-07-12T03:15:03.199136Z","shell.execute_reply":"2024-07-12T03:15:03.229671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer()\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T03:15:03.231637Z","iopub.execute_input":"2024-07-12T03:15:03.231947Z","iopub.status.idle":"2024-07-12T13:54:02.207767Z","shell.execute_reply.started":"2024-07-12T03:15:03.231925Z","shell.execute_reply":"2024-07-12T13:54:02.206280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}